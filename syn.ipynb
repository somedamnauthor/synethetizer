{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#                                                  SYNESTHETIZER\n",
    "\n",
    "Paint a picture out of music\n",
    "\n",
    "https://en.wikipedia.org/wiki/Chromesthesia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grab the notes \n",
    "\n",
    "Sauce - https://github.com/ianvonseggern1/note-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Specify the audio file/path here\n",
    "\"\"\"\n",
    "\n",
    "audio_file = \"VMM Recorder Song 7 Twinkle Twinkle Little Star.mp3\"\n",
    "#audio_file = \"Kanakana Mix 1.2.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup/Imports\n",
    "\"\"\"\n",
    "#!pip3 install pydub\n",
    "#!pip3 install matplotlib\n",
    "#!pip3 install python-Levenshtein\n",
    "#!pip3 install opencv-python\n",
    "\n",
    "import argparse\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import pydub.scipy_effects\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import (\n",
    "    frequency_spectrum,\n",
    "    calculate_distance,\n",
    "    classify_note_attempt_1,\n",
    "    classify_note_attempt_2,\n",
    "    classify_note_attempt_3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main function for grabbing the notes\n",
    "\"\"\"\n",
    "\n",
    "def grab(file, note_file, note_starts_file=None, plot_starts=False, plot_fft_indices=[]):\n",
    "    # If a note file and/or actual start times are supplied read them in\n",
    "    actual_starts = []\n",
    "    if note_starts_file:\n",
    "        with open(note_starts_file) as f:\n",
    "            for line in f:\n",
    "                actual_starts.append(float(line.strip()))\n",
    "\n",
    "    actual_notes = []\n",
    "    if note_file:\n",
    "        with open(note_file) as f:\n",
    "            for line in f:\n",
    "                actual_notes.append(line.strip())\n",
    "\n",
    "    song = AudioSegment.from_file(file)\n",
    "    song = song.high_pass_filter(80, order=4)\n",
    "\n",
    "    starts = predict_note_starts(song, plot_starts, actual_starts)\n",
    "\n",
    "    predicted_notes = predict_notes(song, starts, actual_notes, plot_fft_indices)\n",
    "\n",
    "    print(\"\")\n",
    "    if actual_notes:\n",
    "        print(\"Actual Notes\")\n",
    "        print(actual_notes)\n",
    "    #print(\"Predicted Notes\")\n",
    "    #print(predicted_notes)\n",
    "    return predicted_notes\n",
    "\n",
    "    if actual_notes:\n",
    "        lev_distance = calculate_distance(predicted_notes, actual_notes)\n",
    "        print(\"Levenshtein distance: {}/{}\".format(lev_distance, len(actual_notes)))\n",
    " \n",
    "\n",
    "\"\"\"\n",
    "Function for grabbing the points where notes start\n",
    "\"\"\"\n",
    "\n",
    "def predict_note_starts(song, plot, actual_starts):\n",
    "    # Size of segments to break song into for volume calculations\n",
    "    SEGMENT_MS = 50\n",
    "    # Minimum volume necessary to be considered a note\n",
    "    VOLUME_THRESHOLD = -35\n",
    "    # The increase from one sample to the next required to be considered a note\n",
    "    EDGE_THRESHOLD = 5\n",
    "    # Throw out any additional notes found in this window\n",
    "    MIN_MS_BETWEEN = 100\n",
    "\n",
    "    # Filter out lower frequencies to reduce noise\n",
    "    song = song.high_pass_filter(80, order=4)\n",
    "    # dBFS is decibels relative to the maximum possible loudness\n",
    "    volume = [segment.dBFS for segment in song[::SEGMENT_MS]]\n",
    "\n",
    "    predicted_starts = []\n",
    "    for i in range(1, len(volume)):\n",
    "        if volume[i] > VOLUME_THRESHOLD and volume[i] - volume[i - 1] > EDGE_THRESHOLD:\n",
    "            ms = i * SEGMENT_MS\n",
    "            # Ignore any too close together\n",
    "            if len(predicted_starts) == 0 or ms - predicted_starts[-1] >= MIN_MS_BETWEEN:\n",
    "                predicted_starts.append(ms)\n",
    "\n",
    "    # If actual note start times are provided print a comparison\n",
    "    if len(actual_starts) > 0:\n",
    "        print(\"Approximate actual note start times ({})\".format(len(actual_starts)))\n",
    "        print(\" \".join([\"{:5.2f}\".format(s) for s in actual_starts]))\n",
    "        print(\"Predicted note start times ({})\".format(len(predicted_starts)))\n",
    "        print(\" \".join([\"{:5.2f}\".format(ms / 1000) for ms in predicted_starts]))\n",
    "\n",
    "    # Plot the volume over time (sec)\n",
    "    if plot:\n",
    "        x_axis = np.arange(len(volume)) * (SEGMENT_MS / 1000)\n",
    "        plt.plot(x_axis, volume)\n",
    "\n",
    "        # Add vertical lines for predicted note starts and actual note starts\n",
    "        for s in actual_starts:\n",
    "            plt.axvline(x=s, color=\"r\", linewidth=0.5, linestyle=\"-\")\n",
    "        for ms in predicted_starts:\n",
    "            plt.axvline(x=(ms / 1000), color=\"g\", linewidth=0.5, linestyle=\":\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return predicted_starts\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function for predicting the actual notes\n",
    "\"\"\"\n",
    "\n",
    "def predict_notes(song, starts, actual_notes, plot_fft_indices):\n",
    "    predicted_notes = []\n",
    "    for i, start in enumerate(starts):\n",
    "        sample_from = start + 50\n",
    "        sample_to = start + 550\n",
    "        if i < len(starts) - 1:\n",
    "            sample_to = min(starts[i + 1], sample_to)\n",
    "        segment = song[sample_from:sample_to]\n",
    "        freqs, freq_magnitudes = frequency_spectrum(segment)\n",
    "\n",
    "        predicted = classify_note_attempt_1(freqs, freq_magnitudes)\n",
    "        predicted_notes.append(predicted or \"U\")\n",
    "\n",
    "        # Print general info\n",
    "        print(\"\")\n",
    "        print(\"Note: {}\".format(i))\n",
    "        if i < len(actual_notes):\n",
    "            print(\"Predicted: {} Actual: {}\".format(predicted, actual_notes[i]))\n",
    "        else:\n",
    "            print(\"Predicted: {}\".format(predicted))\n",
    "        print(\"Predicted start: {}\".format(start))\n",
    "        length = sample_to - sample_from\n",
    "        print(\"Sampled from {} to {} ({} ms)\".format(sample_from, sample_to, length))\n",
    "        print(\"Frequency sample period: {}hz\".format(freqs[1]))\n",
    "\n",
    "        # Print peak info\n",
    "        peak_indicies, props = scipy.signal.find_peaks(freq_magnitudes, height=0.015)\n",
    "        print(\"Peaks of more than 1.5 percent of total frequency contribution:\")\n",
    "        for j, peak in enumerate(peak_indicies):\n",
    "            freq = freqs[peak]\n",
    "            magnitude = props[\"peak_heights\"][j]\n",
    "            print(\"{:.1f}hz with magnitude {:.3f}\".format(freq, magnitude))\n",
    "\n",
    "        if i in plot_fft_indices:\n",
    "            plt.plot(freqs, freq_magnitudes, \"b\")\n",
    "            plt.xlabel(\"Freq (Hz)\")\n",
    "            plt.ylabel(\"|X(freq)|\")\n",
    "            plt.show()\n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to get note-y\n",
    "\n",
    "Now that our functions are defined, time to actually grab those notes and slap them onto a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = grab(audio_file, note_file=\"output.txt\")\n",
    "\n",
    "\"\"\"The writing into the note_file part doesn't work. Bleh\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unidentified notes will be identified as 'U'. These notes are removed from the notes list\n",
    "\"\"\"\n",
    "\n",
    "notes = [i for i in notes if i != 'U'] \n",
    "#notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean up the notes \n",
    "\n",
    "Remove any erroneous notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Percentage Threshold for errors - If the frequency of occurence of any notes are less than <percentThresh>% \n",
    "of the total number of ntoes identified, they will be removed. \n",
    "\n",
    "Higher values means a 'looser' accuracy\n",
    "\"\"\"\n",
    "\n",
    "percentThresh = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to count the frequency of notes\n",
    "\"\"\"\n",
    "\n",
    "def CountFrequency(my_list): \n",
    "  \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for item in my_list: \n",
    "        if (item in freq): \n",
    "            freq[item] += 1\n",
    "        else: \n",
    "            freq[item] = 1\n",
    "  \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDict = CountFrequency(notes)\n",
    "freqDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculate actual threshold based on percentThresh specified earlier\"\"\"\n",
    "\n",
    "threshold = sum(freqDict.values())/percentThresh\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Find the notes which have a lesser frequency of occurence as compared to the threshold calculated \"\"\"\n",
    "\n",
    "removeList = []\n",
    "for key,value in freqDict.items():\n",
    "    if value < threshold:\n",
    "        removeList.append(key)\n",
    "        \n",
    "removeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove these notes from the notes list\"\"\"\n",
    "\n",
    "cleanNotes = [i for i in notes if i not in removeList]\n",
    "#cleanNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating a Painting\n",
    "\n",
    "Oh boy it's the big 'un"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Approaches: \n",
    "\n",
    "1. Easy - Generate color grid, create painting out of the grid - Currently following this\n",
    "2. Hard - Grab the color palette, create painting out of the color palette using a model trained on abstract paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup/Imports\"\"\"\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a dictionary showing the mapping between the note and a color\n",
    "\n",
    "One possible mapping is the Scriabin keys - https://en.wikipedia.org/wiki/Clavier_%C3%A0_lumi%C3%A8res\n",
    "\n",
    "TODO - Implement more mappings. Circle of 5ths?\n",
    "\"\"\"\n",
    "\n",
    "scriabinDict = {\"C\":\"#ff0000\", \"C#\": \"#cf9bff\", \"D\": \"#ffff00\", \"D#\":\"#65659a\", \"E\": \"#e4fbff\", \"F\": \"#ae1600\", \"F#\": \"#00cdff\", \"G\": \"#ff6500\", \"G#\": \"#ff00ff\", \"A\": \"#30cd30\", \"A#\": \"#8d8b8d\", \"B\": \"#0000fe\"}\n",
    "#scriabinDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert the list of notes into a list of corresponding hex values\n",
    "\"\"\"\n",
    "\n",
    "hexList = []\n",
    "\n",
    "for note in cleanNotes:\n",
    "    for notekey, notehex in scriabinDict.items():\n",
    "        if note == notekey:\n",
    "            hexList.append(notehex)\n",
    "            \n",
    "#hexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to find the 'best' factor pair\n",
    "\n",
    "The aim is to create a rectangular grid, each cell containing colors from the list. \n",
    "\n",
    "The rectangle closest to looking like an image is one that is neither too tall or too wide. This means a length and\n",
    "breadth that are closest to each other. \n",
    "\n",
    "This function calculates all the possible pairs of factors for the length of the list and picks the pair that has \n",
    "the least difference between the numbers of the pair\n",
    "\"\"\"\n",
    "\n",
    "def findBestFactorPair(n): \n",
    "    newdiff = 10000\n",
    "    for i in range(1, int(pow(n, 1 / 2))+1): \n",
    "        if n % i == 0: \n",
    "            if ((n/i)-i)<newdiff:\n",
    "                xfact = i\n",
    "                yfact = n/i\n",
    "    return xfact,int(yfact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Call the function to find the length and breadth of the rectangular grid we are going to create\n",
    "\n",
    "But before we do that, in order to avoid prime number lengths, the list popped is once if the length of the list is\n",
    "an odd number. \n",
    "\n",
    "This might sound wonky but it feels much faster compared to actually checking for a prime number and handling that\n",
    "case, especially when we are obfuscating the image a bunch. Therefore the length of the list will always be even.\n",
    "\n",
    "TODO - In case the implementation of the note-grabbing gets really accurate we might need to change this to reflect\n",
    "a similar level of accuracy.\n",
    "\"\"\"\n",
    "\n",
    "if len(hexList)%2 != 0:\n",
    "    hexList.pop()\n",
    "\n",
    "xfact,yfact = findBestFactorPair(len(hexList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Time to get the grid up!\n",
    "\n",
    "Doing a bunch of stuff with matplotlib so that it ends up with a big image that doesn't have those pesky ticks and\n",
    "labels\n",
    "\n",
    "The final image is written onto a file called \"Grid.png\" at the same level as this notebook\n",
    "\"\"\"\n",
    "\n",
    "from matplotlib.colors import to_rgba_array\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.tick_params(left=False,\n",
    "                bottom=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False)\n",
    "\n",
    "plt.imshow(to_rgba_array(hexList).reshape(xfact,yfact,4))\n",
    "\n",
    "plt.savefig('Grid.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now give it life! \n",
    "\n",
    "Turn this grid into something far greater than it could've dreamt of being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here's the wobbly bit. We're doing a bunch of fuckery with this grid. \n",
    "\n",
    "The #Intial Pass is meant to get as close to the targeted aesthetic as possible\n",
    "The #Smoothening Pass is meant to give it a more blurred, muted look\n",
    "\n",
    "Both of these passes involve the oilPainting, stylization(for watercolor) and a Gaussian blur\n",
    "\n",
    "TODO - Stop winging this\n",
    "\"\"\"\n",
    "\n",
    "res = img\n",
    "\n",
    "#Initial Pass\n",
    "for i in range(5):\n",
    "    res = cv2.xphoto.oilPainting(res, 7, 1)\n",
    "    res = cv2.stylization(res, sigma_s=60, sigma_r=0.6)\n",
    "    res = cv2.xphoto.oilPainting(res, 7, 1)\n",
    "    res = cv2.blur(res,(5,5))\n",
    "  \n",
    "#Smoothening Pass\n",
    "for i in range(20):\n",
    "    res = cv2.xphoto.oilPainting(res, 7, 1)\n",
    "    res = cv2.blur(res,(5,5))\n",
    "        \n",
    "#plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write the resulting image 'res' into a file called outimg.png stored at the same level as the notebook\n",
    "\"\"\"\n",
    "\n",
    "cv2.imwrite(\"outimg.png\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
